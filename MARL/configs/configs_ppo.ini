[MODEL_CONFIG]
; if "False", parameters are initialzed randomly
use_xavier_initialization = True
; Attention configs
use_attention_module = True
num_heads = 3
dropout_p = 0.3
; for the RMSprop optimizer
epsilon = 1e-5
alpha = 0.99
reward_gamma = 0.99
MAX_GRAD_NORM = 5
; roll out n steps
ROLL_OUT_N_STEPS = 100
; only remember the latest ROLL_OUT_N_STEPS
MEMORY_CAPACITY = 100
; only use the latest ROLL_OUT_N_STEPS for training A2C
BATCH_SIZE = 100
ENTROPY_REG = 0.01
; seeds for pytorch, 0, 2000, 2021
torch_seed = 0
TARGET_UPDATE_STEPS = 3
TARGET_TAU = 1.0

; concurrent
training_strategy = concurrent
actor_hidden_size = 128
critic_hidden_size = 128
action_masking = False
; "regionalR", "global_R"
reward_type = global_R

[TRAIN_CONFIG]
MAX_EPISODES = 1000
EPISODES_BEFORE_TRAIN = 1
EVAL_EPISODES = 3
EVAL_INTERVAL = 50
reward_scale = 20.
actor_lr = 5e-4
critic_lr = 5e-4
test_seeds = 150,175,200,325,350,375,400,425,450,475,500,525,550,575, 0,25,50,75,100,125,


[ENV_CONFIG]
; seed for the training environment: 0, 2000, 2024
seed = 2000
; [Hz]
simulation_frequency = 15
; time step
# A converged model (in a *0* PriorityVehicle environment) should rarely need more than 20 time steps.
duration = 30
policy_frequency = 5
COLLISION_REWARD = 200
HIGH_SPEED_REWARD = 1
PRIORITY_SPEED_COST = 0
HEADWAY_COST = 4
HEADWAY_TIME = 1.2
MERGING_LANE_COST = 4
PRIORITY_LANE_COST = 0.5
LANE_CHANGE_COST = 0.05
; ^only used in multilane environment
num_CAV = 4
num_HDV = 4
;num_PV = 1