model:
  # --- General training arguments ---
  train_episodes: 1000
  # Total episodes to train
  hidden_size: 256
  # network hidden size, for both actor and critic
  eval_interval: 50
  # How many training episodes to run an evaluation
  test_seeds:
    - 100
    - 125
    - 150
  # List of seeds for evaluation

  # --- Algorithm specific arguments ---
  learning_rate: !!float 0.01
  # the learning rate of the optimizer
  buffer_size: !!int 1_000_000
  # the replay memory buffer size
  gamma: 0.95
  # the discount factor gamma
  tau: 0.01
  # target smoothing coefficient
  batch_size: 1024
  # the batch size of samples from the reply memory
  exploration_noise: 0.1
  # the scale of exploration noise
  learning_starts: !!int 2_000
  # after this many timesteps, agents begin learning.
  policy_frequency: 100
  # the frequency of training policy (delayed)
  noise_clip: 0.5
  # noise clip parameter of the Target Policy Smoothing Regularization

  reward_scale: 25.0
  # scales the reward by a factor of (1 / reward_scale)

  curriculum_episodes: 0  
  # curriculum training not supported (non-zeros value will break)
