seed: 2000

model:
  batch_size: 10_000 # will remember and interact with the environment for at most batch_size steps
  update_epochs: 1 # each train_model() called fill update `update_epochs` times
  entropy_reg: 0.01

  hidden_size: 256 # network hidden size, for both actor and critic

  rollout_steps: 125
  train_episodes: 2000 # training episodes
  curriculum_episodes: 1000 # how many curriculum episdoes?
  eval_interval: 50
  learning_rate: 3e-4
  test_seeds:
    - 100
    - 125
    - 150

env:
  simulation_frequency: 15 # [Hz]
  policy_frequency: 5      # [Hz]
  duration: 25             # (seconds)
  # A converged model (in a *0* PriorityVehicle environment) should rarely need more than 20 seconds.

  # Rewards
  COLLISION_COST: 30
  HIGH_SPEED_REWARD: 1
  HEADWAY_COST: 4
  HEADWAY_TIME: 1.5
  MERGING_LANE_COST: 4
  PRIORITY_LANE_COST: 1
  LANE_CHANGE_COST: 0.5

  # Vehicle count
  num_CAV: 4
  num_HDV: 3
  # num_PV: 1  # Uncomment if needed
  # num_HDV excludes the priority vehicle count
